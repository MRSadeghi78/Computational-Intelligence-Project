{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: SVM"
      ],
      "metadata": {
        "id": "VvHpLliGBDis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "fOqHQnUyRBLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "qAZq3koCbV8Y",
        "outputId": "11d10cc0-5092-4c87-d6d6-72e97376dc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-139498d0-5bbb-430d-a671-9d77f55ee51e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_title</th>\n",
              "      <th>user_id</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>title</th>\n",
              "      <th>comment</th>\n",
              "      <th>advantages</th>\n",
              "      <th>disadvantages</th>\n",
              "      <th>recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90213</td>\n",
              "      <td>شارژر همراه شیاومی مدل NDY-02-AN با ظرفیت 1000...</td>\n",
              "      <td>3862150</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>واقعاً عالیه</td>\n",
              "      <td>سلام، قبل اینکه نظرم رو بگم میخواستم به یک موض...</td>\n",
              "      <td>[\"عمر طولانی\\r\",\"افت بسیار کم میزان شارژ\\r\",\"ا...</td>\n",
              "      <td>[\"ندارد\"]</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59473</td>\n",
              "      <td>یدک پولیشر میکروفایبر مهسان مدل 20119</td>\n",
              "      <td>626843</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>خیلی سخت حوله اش در میاد</td>\n",
              "      <td>گیره های فلزی خیلی سخت تا میشوند و لذا حوله را...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>not_recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133722</td>\n",
              "      <td>لپ تاپ 15 اینچی ایسوس مدل N501VW - A</td>\n",
              "      <td>497032</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>اقرار بیش از حد در ایراد گرفتن</td>\n",
              "      <td>سلام دوستان،،_x000D_\\nمنم مثه بعضی از دوستان ق...</td>\n",
              "      <td>[\"همه چیز که تو مشخصات اومده بجز 3 مورد کوچیک\"]</td>\n",
              "      <td>[\"تاچ پدش میتونست بهتر باشه از نظر سرعت پاسخ گ...</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>148509</td>\n",
              "      <td>اسپیکر بلوتوثی دیووم مدل Bluetune bean</td>\n",
              "      <td>574130</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>بسیار خوب</td>\n",
              "      <td>من چند سالی هست که این اسپیکرو خریدم و واقعا ح...</td>\n",
              "      <td>[\"کیفیت ساخت بسیار خوب\\r\",\"کیفیت صدا بسیار عال...</td>\n",
              "      <td>[\"ندارد\"]</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5107</td>\n",
              "      <td>هارددیسک اکسترنال سیگیت مدل Backup Plus Deskto...</td>\n",
              "      <td>794316</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>هارد با کیفیت و ظاهر شیک</td>\n",
              "      <td>نزدیک به دو ساله که این هارد رو خریدم. استفاده...</td>\n",
              "      <td>[\"کیفیت ساخت خوب\\r\",\"ظاهر ساده و زیبا\\r\",\"صدای...</td>\n",
              "      <td>[\"عدم مقاومت در برابر ضربه\\r\",\"عدم سهولت جا به...</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48077</th>\n",
              "      <td>842976</td>\n",
              "      <td>لیوان گامین گلس مدل محک بسته 6 عددی</td>\n",
              "      <td>2333505</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>بی کیفیت</td>\n",
              "      <td>کاملابی کیفیت، تو هر قیمتی اصلا ارزش خرید نداره</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>not_recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48078</th>\n",
              "      <td>362029</td>\n",
              "      <td>کتاب سفید و قرمز نسخه بارسلونا</td>\n",
              "      <td>8369747</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>عالی بود  خون دن داره</td>\n",
              "      <td>عالیییییییییییییییییییی</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48079</th>\n",
              "      <td>818381</td>\n",
              "      <td>بالش بادی پورگونر مدل KMG</td>\n",
              "      <td>8027276</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ارزش خرید نداره</td>\n",
              "      <td>اندازه بالش بسیار کوچک هست بیشتر بدرد بچه ۲ سا...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>not_recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48080</th>\n",
              "      <td>549845</td>\n",
              "      <td>شید آباژور آرام مدل SH45/01</td>\n",
              "      <td>4979401</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>بسیار تمیز و زیبا</td>\n",
              "      <td>بسیار تمیز و زیبا...من که خیلی راضیم</td>\n",
              "      <td>[\"کاملا مطابق با عکس\\r\",\"ساخت بسیار تمیز\"]</td>\n",
              "      <td>[\"ندارد\"]</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48081</th>\n",
              "      <td>820985</td>\n",
              "      <td>واکس کفش ساتل مدل 20 حجم 60 میلی لیتر</td>\n",
              "      <td>568208</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>خوبه و غلیظه</td>\n",
              "      <td>واکس خوبیه..</td>\n",
              "      <td>[\"روغنیه\"]</td>\n",
              "      <td>[\"ندیدم\"]</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48082 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-139498d0-5bbb-430d-a671-9d77f55ee51e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-139498d0-5bbb-430d-a671-9d77f55ee51e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-139498d0-5bbb-430d-a671-9d77f55ee51e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       product_id  ...        recommend\n",
              "0           90213  ...      recommended\n",
              "1           59473  ...  not_recommended\n",
              "2          133722  ...      recommended\n",
              "3          148509  ...      recommended\n",
              "4            5107  ...      recommended\n",
              "...           ...  ...              ...\n",
              "48077      842976  ...  not_recommended\n",
              "48078      362029  ...      recommended\n",
              "48079      818381  ...  not_recommended\n",
              "48080      549845  ...      recommended\n",
              "48081      820985  ...      recommended\n",
              "\n",
              "[48082 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install rarfile\n",
        "\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.drive import GoogleDrive\n",
        "from rarfile import RarFile\n",
        "import pandas as pd\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1OS8iDV2TjI4nnixNV7KjQypUEAv9n714'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('train.rar')\n",
        "with RarFile('train.rar', 'r') as zip:\n",
        "    zip.extractall(path='./data')\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6bjZHKqd7V6"
      },
      "outputs": [],
      "source": [
        "# train_data = train_data.drop(['product_id'], axis=1)\n",
        "# train_data = train_data.drop(['product_title'], axis=1)\n",
        "# train_data = train_data.drop(['user_id'], axis=1)\n",
        "# train_data = train_data.drop(['likes'], axis=1)\n",
        "# train_data = train_data.drop(['dislikes'], axis=1)\n",
        "# train_data = train_data.drop(['advantages'], axis=1)\n",
        "# train_data = train_data.drop(['disadvantages'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_ECFOpRfxQD"
      },
      "outputs": [],
      "source": [
        "# for column_name in train_data.columns:\n",
        "#         train_data[column_name] = train_data[column_name].fillna(train_data[column_name].mode()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train and target columns"
      ],
      "metadata": {
        "id": "O9zwCkjfR1lq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq_T0Erig-Hf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_target = le.fit_transform(train_data.recommend)\n",
        "train_data = train_data.title + \" \" + train_data.comment\n",
        "train_data = train_data.astype(str)\n",
        "# train_data.comment = train_data.comment.astype(str)\n",
        "# train_data.title = train_data.title.astype(str)\n",
        "# train_data = train_data.drop(['recommend'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train and validation data"
      ],
      "metadata": {
        "id": "m4pgvcdcSAqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, validation_x, train_y, validation_y = train_test_split(train_data, train_target, test_size = 0.1, random_state=42)\n",
        "# train_x, train_y = train_data, train_target"
      ],
      "metadata": {
        "id": "6Pic4tnOxaJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preporocess data"
      ],
      "metadata": {
        "id": "_wcZnaJvSIK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "\n",
        "from hazm import *\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "normalizer = Normalizer(persian_numbers=False)\n",
        "lemmatizer = Lemmatizer()\n",
        "stop_words = stopwords_list()\n",
        "\n",
        "def remove_hyperlink(word):\n",
        "    word = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \"\", word[::-1])\n",
        "    word = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \"\", word[::-1])\n",
        "    return word\n",
        "\n",
        "def to_lower(word):\n",
        "    return word.lower()\n",
        "\n",
        "def remove_number(word):\n",
        "    return re.sub(r'\\d+', '', word)\n",
        "\n",
        "def remove_punctuation(word):\n",
        "    word = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "    return word.replace(\"،\", \"\")\n",
        "    \n",
        "def remove_whitespace(word):\n",
        "    return word.strip()\n",
        "\n",
        "def replace_newline(word):\n",
        "    return word.replace('\\n','')\n",
        "\n",
        "def remove_stop_words_and_lammatize(word):\n",
        "    tokens = word_tokenize(word)\n",
        "    new_tokens = [lemmatizer.lemmatize(x) for x in tokens]\n",
        "    new_word = ' '.join(new_tokens)\n",
        "    return new_word\n",
        "\n",
        "def normalize(word):\n",
        "    return normalizer.normalize(word)\n",
        "\n",
        "def removeHtmlTags(word):\n",
        "    return re.sub('<[^>]*>', ' ', word)\n",
        "\n",
        "def removeEnglishLetters(word):\n",
        "    return re.sub('[A-Za-z]',' ', word)\n",
        "\n",
        "def removeUnnecessaryPersianCharacters(word):\n",
        "    return re.sub('[ء]',' ', word)\n",
        "\n",
        "def clean_up_pipeline(sentence):\n",
        "    cleaning_utils = [\n",
        "                    #   to_lower,\n",
        "                    #   remove_hyperlink,\n",
        "                    #   replace_newline,\n",
        "                    #   remove_number,\n",
        "                    #   remove_punctuation,\n",
        "                    #   remove_whitespace,\n",
        "                      normalize,\n",
        "                    #   remove_stop_words_and_lammatize,\n",
        "                    #   removeHtmlTags,\n",
        "                    #   removeEnglishLetters,\n",
        "                    #   removeUnnecessaryPersianCharacters\n",
        "                     ]\n",
        "    for o in cleaning_utils:\n",
        "        sentence = o(sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "mJSgXZH4ukgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_x[1])\n",
        "train_x = [clean_up_pipeline(o) for o in train_x]\n",
        "# print(train_x[1])"
      ],
      "metadata": {
        "id": "pU7pPVrbUsks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "Sz3AEopcSXTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "text_clf_svc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf-svm', LinearSVC(C=0.7, multi_class=\"crammer_singer\", max_iter=50000)),\n",
        "])\n",
        "\n",
        "text_clf_svc = text_clf_svc.fit(train_x, train_y)\n",
        "predicted = text_clf_svc.predict(validation_x)\n",
        "np.mean(predicted == validation_y)"
      ],
      "metadata": {
        "id": "L1wm9jxsvGFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e265a2-473d-41b4-8e97-5acf22766ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9378249116240382"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict test dataset"
      ],
      "metadata": {
        "id": "da6qdX_GSghr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "test = pd.read_csv(io.BytesIO(uploaded['CI_test.csv']))\n",
        "test_x = test.title + \" \" + test.comment\n",
        "test_x = test_x.astype(str)"
      ],
      "metadata": {
        "id": "1OiXwoYmwhhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [clean_up_pipeline(o) for o in test_x]\n",
        "predicted_svc = text_clf_svc.predict(x_test)\n",
        "pred_test = le.inverse_transform(predicted_svc)\n",
        "pred_test"
      ],
      "metadata": {
        "id": "-n7lOYR9vNO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b7a213-a320-4acc-8ed5-934722325f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['recommended', 'not_recommended', 'not_recommended', ...,\n",
              "       'recommended', 'not_recommended', 'not_recommended'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame({'id': test.id,\n",
        "                       'recommend': pred_test})\n",
        "output.to_csv('submission4.csv', index=False)"
      ],
      "metadata": {
        "id": "HQYF54JZvPwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: RNN"
      ],
      "metadata": {
        "id": "_1I5S_ubA7h0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "St5_LhZWU_fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('data/train.csv')"
      ],
      "metadata": {
        "id": "RRlk8d2pM4-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ],
      "metadata": {
        "id": "m8H5Rf9yVDsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(raw_data):\n",
        "    structured_data = []\n",
        "    for _, row in raw_data.iterrows():\n",
        "        main_text = str(row['title']) + ' ' + str(row['comment'])\n",
        "        likes = row['likes']\n",
        "        dislikes = row['dislikes']\n",
        "        recommend = row['recommend']\n",
        "\n",
        "        tokens = tokenizer(main_text)\n",
        "        structured_data.append({\n",
        "            'recommend': 1 if recommend == 'recommended' else 0,\n",
        "            'tokens': tokens\n",
        "        })\n",
        "    return structured_data"
      ],
      "metadata": {
        "id": "yD5h7yINBUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    text = clean_up_pipeline(text)\n",
        "    text = re.sub('\\s+', ' ', text).strip()\n",
        "    return word_tokenize(text)"
      ],
      "metadata": {
        "id": "NE6W87HJBAcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_words(comments):\n",
        "    temp = [token for token in (comment['tokens'] for comment in comments)];\n",
        "    res = set()\n",
        "    for t in temp:\n",
        "      for b in t:\n",
        "        res.add(b)\n",
        "    return res"
      ],
      "metadata": {
        "id": "bgTx7wCNDV6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_words(hashed_word):\n",
        "    result = {w: index for index, w in enumerate(hashed_word)}\n",
        "    result['reserved_for_new_words'] = len(hashed_word) + 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "mdzGZwf4Jrtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_train_data(structured_data, indexed_words):\n",
        "    x, y = [], []\n",
        "    for data in structured_data:\n",
        "        x.append([indexed_words[token] for token in data['tokens']])\n",
        "        y.append(data['recommend'])\n",
        "    return np.asarray(x), np.asarray(y)"
      ],
      "metadata": {
        "id": "hZFrVDAeFfCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "TfO3gGJVVJgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "\n",
        "def model_generator(word_number):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(word_number + 1, 110))\n",
        "    model.add(Bidirectional(LSTM(110, dropout=0.2, recurrent_dropout=0.2)))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "iGaLmhBcNTgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "KQ6v-W5lVL0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "structured_data = clean_data(raw_data)\n",
        "hashed_word = hash_words(structured_data)\n",
        "indexed_words = index_words(hashed_word)\n",
        "x, y = compute_train_data(structured_data, indexed_words)\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "max_length_of_comment = 200\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_length_of_comment)\n",
        "x_validation = sequence.pad_sequences(x_validation, maxlen=max_length_of_comment)"
      ],
      "metadata": {
        "id": "sw0B_Q5EHGBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "epoch = 1\n",
        "model = model_generator(len(indexed_words))\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epoch,\n",
        "              validation_data=(x_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMcE3TSHSHc",
        "outputId": "68dd3cc2-23bf-4a51-93d5-6081809b0918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 110)         5828020   \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 220)              194480    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 442       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,022,942\n",
            "Trainable params: 6,022,942\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2164/2164 [==============================] - 2014s 926ms/step - loss: 0.2280 - accuracy: 0.9144 - val_loss: 0.1686 - val_accuracy: 0.9372\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9c035aff10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict test data"
      ],
      "metadata": {
        "id": "4RIhUxvjVSl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_test = pd.read_csv(io.BytesIO(uploaded['CI_test.csv']))\n",
        "\n",
        "predicts_test = []\n",
        "for index, row in raw_data_test.iterrows():\n",
        "    pred_dict = dict()\n",
        "\n",
        "    title = row['title']\n",
        "    comment = row['comment']\n",
        "    text = str(title) + ' ' + str(comment)\n",
        "\n",
        "    \n",
        "    tokens = tokenizer(text)\n",
        "    indexes_of_tokens = [[indexed_words.get(token, indexed_words['reserved_for_new_words']) for token in tokens]]\n",
        "\n",
        "    seq_result = sequence.pad_sequences(indexes_of_tokens, maxlen=max_length_of_comment)\n",
        "\n",
        "    result = model.predict(seq_result)\n",
        "    pred_dict['id'] = row['id']\n",
        "    if result[0][0] > result[0][1]:\n",
        "      pred_dict['recommend'] = 'not_recommended'\n",
        "    else:\n",
        "      pred_dict['recommend'] = 'recommended'\n",
        "\n",
        "    predicts_test.append(pred_dict)"
      ],
      "metadata": {
        "id": "cj4NtqeQIzaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "keys = predicts_test[0].keys()\n",
        "\n",
        "with open('submission10.csv', 'w', newline='') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(predicts_test)"
      ],
      "metadata": {
        "id": "ap0_GqEZJ6fK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "CI_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}